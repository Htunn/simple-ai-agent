services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        BUILD_DATE: ${BUILD_DATE:-2024-01-01}
        VCS_REF: ${VCS_REF:-dev}
        VERSION: ${VERSION:-1.0.0}
    image: simple-ai-agent:${VERSION:-latest}
    container_name: simple-ai-agent
    ports:
      - "${APP_PORT:-8000}:8000"
    environment:
      # Database configuration — always use the internal Docker service hostname.
      # Do NOT pass DATABASE_URL from the host environment; construct from parts
      # so a local-dev .env with localhost never leaks into the container.
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-aiagent}:${POSTGRES_PASSWORD:-aiagent_password}@postgres:5432/${POSTGRES_DB:-aiagent}
      - REDIS_URL=redis://redis:6379/0

      # Bot tokens (should be in .env file)
      - DISCORD_TOKEN=${DISCORD_TOKEN}
      - TELEGRAM_TOKEN=${TELEGRAM_TOKEN}
      - SLACK_BOT_TOKEN=${SLACK_BOT_TOKEN}
      - SLACK_SIGNING_SECRET=${SLACK_SIGNING_SECRET}
      - GITHUB_TOKEN=${GITHUB_TOKEN}

      # Application settings
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gpt-4}

      # MCP configuration
      - MCP_CONFIG_PATH=/app/.mcp-config.json

      # Kubernetes configuration (if using K8s MCP)
      # Always use the in-container path; host kubeconfig dir is mounted at /app/.kube
      - KUBECONFIG=/app/.kube/config
      - K8S_CONTEXT=${K8S_CONTEXT:-}

      # Performance tuning
      - WORKERS=${WORKERS:-1}
      - MAX_CONNECTIONS=${MAX_CONNECTIONS:-100}

      # Security
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE:-60}

    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

    volumes:
      # Persistent logs
      - ./logs:/app/logs
      # Kubernetes config: a patched copy of the host kubeconfig where
      # 127.0.0.1 is replaced with host.docker.internal so SSH-tunnel
      # endpoints and SOCKS proxies are reachable from inside the container.
      # Generated by start_production.sh into ./data/kube/config.
      - ./data/kube/config:/app/.kube/config:ro
      # Optional: MCP config overrides
      - ./.mcp-config.json:/app/.mcp-config.json:ro

    extra_hosts:
      # Allows the container to reach the host's loopback (SSH tunnel / SOCKS proxy)
      - "host.docker.internal:host-gateway"

    restart: unless-stopped

    networks:
      - aiagent-network

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

    # Resource limits for production
    deploy:
      resources:
        limits:
          cpus: "${APP_CPU_LIMIT:-2.0}"
          memory: ${APP_MEMORY_LIMIT:-2G}
        reservations:
          cpus: "${APP_CPU_RESERVATION:-0.5}"
          memory: ${APP_MEMORY_RESERVATION:-512M}

    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # Security options
    security_opt:
      - no-new-privileges:true

    # Read-only root filesystem (except specific mounts)
    # Uncomment for enhanced security after testing
    # read_only: true
    # tmpfs:
    #   - /tmp
    #   - /app/logs

  postgres:
    image: postgres:16-alpine
    container_name: simple-ai-agent-postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-aiagent}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-aiagent_password}
      - POSTGRES_DB=${POSTGRES_DB:-aiagent}
      # Performance tuning
      - POSTGRES_MAX_CONNECTIONS=${POSTGRES_MAX_CONNECTIONS:-200}
      - POSTGRES_SHARED_BUFFERS=${POSTGRES_SHARED_BUFFERS:-256MB}
      - POSTGRES_EFFECTIVE_CACHE_SIZE=${POSTGRES_EFFECTIVE_CACHE_SIZE:-1GB}

    ports:
      - "${POSTGRES_PORT:-5432}:5432"

    volumes:
      - postgres-data:/var/lib/postgresql/data
      # Optional: Custom postgresql.conf
      # - ./config/postgresql.conf:/etc/postgresql/postgresql.conf:ro

    # PostgreSQL configuration for performance
    command: >
      postgres
      -c shared_buffers=${POSTGRES_SHARED_BUFFERS:-256MB}
      -c effective_cache_size=${POSTGRES_EFFECTIVE_CACHE_SIZE:-1GB}
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=4MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=4
      -c max_parallel_workers_per_gather=2
      -c max_parallel_workers=4
      -c max_parallel_maintenance_workers=2

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-aiagent}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

    restart: unless-stopped

    networks:
      - aiagent-network

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${POSTGRES_CPU_LIMIT:-1.0}"
          memory: ${POSTGRES_MEMORY_LIMIT:-1G}
        reservations:
          cpus: "${POSTGRES_CPU_RESERVATION:-0.25}"
          memory: ${POSTGRES_MEMORY_RESERVATION:-256M}

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # Security
    security_opt:
      - no-new-privileges:true

  redis:
    image: redis:7-alpine
    container_name: simple-ai-agent-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"

    volumes:
      - redis-data:/data
      # Optional: Custom redis.conf
      # - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro

    # Redis configuration for persistence and performance
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory ${REDIS_MAXMEMORY:-512mb}
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --tcp-backlog 511
      --timeout 0
      --tcp-keepalive 300
      --loglevel notice

    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s

    restart: unless-stopped

    networks:
      - aiagent-network

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "${REDIS_CPU_LIMIT:-0.5}"
          memory: ${REDIS_MEMORY_LIMIT:-512M}
        reservations:
          cpus: "${REDIS_CPU_RESERVATION:-0.1}"
          memory: ${REDIS_MEMORY_RESERVATION:-128M}

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    # Security
    security_opt:
      - no-new-privileges:true

  # Optional: Redis Commander for debugging and monitoring
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: simple-ai-agent-redis-commander
    environment:
      - REDIS_HOSTS=local:redis:6379
      - HTTP_USER=${REDIS_COMMANDER_USER:-admin}
      - HTTP_PASSWORD=${REDIS_COMMANDER_PASSWORD:-admin}

    ports:
      - "${REDIS_COMMANDER_PORT:-8081}:8081"

    depends_on:
      - redis

    networks:
      - aiagent-network

    profiles:
      - debug

    restart: unless-stopped

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 128M

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # Optional: PostgreSQL Admin (pgAdmin) for database management
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: simple-ai-agent-pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_EMAIL:-admin@example.com}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_PASSWORD:-admin}
      - PGADMIN_CONFIG_SERVER_MODE=False
      - PGADMIN_CONFIG_MASTER_PASSWORD_REQUIRED=False

    ports:
      - "${PGADMIN_PORT:-8082}:80"

    depends_on:
      - postgres

    volumes:
      - pgadmin-data:/var/lib/pgadmin

    networks:
      - aiagent-network

    profiles:
      - debug

    restart: unless-stopped

    # Resource limits
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ────────────────────────────────────────────────────────────
  # AIOps Monitoring Stack
  # ────────────────────────────────────────────────────────────

  prometheus:
    image: prom/prometheus:v2.51.2
    container_name: simple-ai-agent-prometheus
    user: "65534:65534"
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"

    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./config/alert_rules.yml:/etc/prometheus/alert_rules.yml:ro
      - prometheus-data:/prometheus

    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=${PROMETHEUS_RETENTION:-15d}"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"

    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

    restart: unless-stopped

    networks:
      - aiagent-network

    depends_on:
      - alertmanager

    deploy:
      resources:
        limits:
          cpus: "${PROMETHEUS_CPU_LIMIT:-0.5}"
          memory: ${PROMETHEUS_MEMORY_LIMIT:-512M}
        reservations:
          cpus: "0.1"
          memory: 128M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    security_opt:
      - no-new-privileges:true

  alertmanager:
    image: prom/alertmanager:v0.27.0
    container_name: simple-ai-agent-alertmanager
    user: "65534:65534"
    ports:
      - "${ALERTMANAGER_PORT:-9093}:9093"

    volumes:
      - ./config/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager-data:/alertmanager

    command:
      - "--config.file=/etc/alertmanager/alertmanager.yml"
      - "--storage.path=/alertmanager"
      - "--web.external-url=http://localhost:${ALERTMANAGER_PORT:-9093}"
      - "--cluster.advertise-address=0.0.0.0:9093"

    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:9093/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    restart: unless-stopped

    networks:
      - aiagent-network

    deploy:
      resources:
        limits:
          cpus: "0.25"
          memory: 128M

    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

    security_opt:
      - no-new-privileges:true

  grafana:
    image: grafana/grafana:10.4.2
    container_name: simple-ai-agent-grafana
    ports:
      - "${GRAFANA_PORT:-3000}:3000"

    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-changeme}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_DOMAIN=${GRAFANA_DOMAIN:-localhost}
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_INSTALL_PLUGINS=${GRAFANA_PLUGINS:-}
      # Auto-provision Prometheus datasource
      - GF_DATASOURCES_DEFAULT_NAME=Prometheus
      - GF_AUTH_ANONYMOUS_ENABLED=false

    volumes:
      - grafana-data:/var/lib/grafana
      - ./config/grafana/provisioning:/etc/grafana/provisioning:ro

    healthcheck:
      test:
        [
          "CMD-SHELL",
          'wget -qO- http://localhost:3000/api/health | grep -q ''"database": "ok"''',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

    restart: unless-stopped

    networks:
      - aiagent-network

    depends_on:
      prometheus:
        condition: service_healthy

    deploy:
      resources:
        limits:
          cpus: "${GRAFANA_CPU_LIMIT:-0.5}"
          memory: ${GRAFANA_MEMORY_LIMIT:-256M}
        reservations:
          cpus: "0.1"
          memory: 64M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    security_opt:
      - no-new-privileges:true

volumes:
  postgres-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/postgres

  redis-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/redis

  pgadmin-data:
    driver: local

  prometheus-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/prometheus

  alertmanager-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/alertmanager

  grafana-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${DATA_DIR:-./data}/grafana

networks:
  aiagent-network:
    driver: bridge
    ipam:
      config:
        - subnet: ${NETWORK_SUBNET:-172.25.0.0/16}
